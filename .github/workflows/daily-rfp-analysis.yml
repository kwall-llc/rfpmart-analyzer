name: Daily RFP Analysis

on:
  schedule:
    # Run daily at 9 AM EST (1 PM UTC)
    - cron: '0 13 * * *'
  workflow_dispatch:
    inputs:
      since_date:
        description: 'Only process RFPs since this date (YYYY-MM-DD)'
        required: false
        type: string
      force_full_run:
        description: 'Force full analysis workflow'
        required: false
        type: boolean
        default: false

env:
  NODE_ENV: production

permissions:
  contents: write  # Allow pushing to repository
  issues: write    # Allow creating GitHub issues

jobs:
  rfp-analysis:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install chromium

      - name: Build project
        run: npm run build

      - name: Create environment file
        run: |
          echo "RFPMART_USERNAME=${{ secrets.RFPMART_USERNAME }}" >> .env
          echo "RFPMART_PASSWORD=${{ secrets.RFPMART_PASSWORD }}" >> .env
          echo "RFP_CATEGORY_URL=https://www.rfpmart.com/web-design-and-development-rfp-government-contract.html" >> .env
          echo "MIN_BUDGET_ACCEPTABLE=50000" >> .env
          echo "MIN_BUDGET_PREFERRED=100000" >> .env
          echo "DATA_DIRECTORY=./data" >> .env
          echo "REPORTS_DIRECTORY=./data/reports" >> .env
          echo "RFPS_DIRECTORY=./data/rfps" >> .env
          echo "DATABASE_PATH=./data/database.sqlite" >> .env
          echo "LOG_LEVEL=info" >> .env
          echo "LOG_FILE=./logs/rfpmart-analyzer.log" >> .env
          echo "NODE_ENV=production" >> .env
          echo "HIGHER_ED_KEYWORDS=university,college,school,education,academic,campus,student,institution,district,system" >> .env
          echo "CMS_KEYWORDS_PREFERRED=drupal,wordpress,modern campus" >> .env
          echo "CMS_KEYWORDS_ACCEPTABLE=joomla,craft,contentful,strapi,sitecore,umbraco" >> .env
          echo "PROJECT_TYPE_KEYWORDS=redesign,migration,rebuild,modernize,refresh,overhaul,revamp" >> .env
          echo "TECHNICAL_KEYWORDS=responsive,mobile,accessibility,wcag,ada,508,mobile-first,progressive" >> .env
          echo "LOCATION_PREFERRED=united states,usa,america,north america" >> .env
          echo "LOCATION_ACCEPTABLE=canada,remote,virtual,distributed,online" >> .env
          echo "AI_PROVIDER=openai" >> .env
          echo "AI_OPENAI_API_KEY=${{ secrets.AI_OPENAI_API_KEY }}" >> .env
          echo "AI_OPENAI_MODEL=gpt-4" >> .env
          echo "CLEANUP_ENABLED=true" >> .env
          echo "CLEANUP_POOR_FIT_THRESHOLD=30" >> .env
          echo "CLEANUP_REJECTED_THRESHOLD=50" >> .env

      - name: Create data directories
        run: |
          mkdir -p data/rfps
          mkdir -p data/reports
          mkdir -p data-store
          mkdir -p logs

      - name: Download persistent database
        run: |
          echo "Downloading persistent database from data-store branch..."
          
          # Create orphan branch for data storage if it doesn't exist
          git fetch origin data-store || {
            echo "data-store branch doesn't exist yet, will create it after analysis"
            echo "NO_PERSISTENT_DATA=true" >> $GITHUB_ENV
            exit 0
          }
          
          # Switch to data-store branch and copy database
          git checkout -b data-store origin/data-store
          
          if [ -f "database.sqlite" ]; then
            echo "âœ… Found persistent database"
            cp database.sqlite ./data-store/database.sqlite
            
            # Get database info
            echo "Database size: $(stat -f%z database.sqlite 2>/dev/null || stat -c%s database.sqlite) bytes"
            echo "Database modified: $(stat -f%Sm database.sqlite 2>/dev/null || stat -c%y database.sqlite)"
            
            echo "PERSISTENT_DATABASE_FOUND=true" >> $GITHUB_ENV
          else
            echo "â„¹ï¸ No persistent database found on data-store branch"
            echo "PERSISTENT_DATABASE_FOUND=false" >> $GITHUB_ENV
          fi
          
          # Switch back to main branch
          git checkout main
          
          # Show what we have
          echo "Data store directory contents:"
          ls -la data-store/ || echo "data-store directory empty"

      - name: Initialize application and database
        run: |
          echo "Initializing RFP Mart Analyzer..."
          
          # Verify environment file was created
          if [ -f ".env" ]; then
            echo "âœ… Environment file exists"
            echo "Environment variables:"
            grep -E "^[A-Z_]+=" .env | head -5
          else
            echo "âŒ Environment file missing"
            exit 1
          fi
          
          # Show Node.js and npm versions
          echo "Node.js version: $(node --version)"
          echo "npm version: $(npm --version)"
          
          # Pre-create directory structure for GitHub Actions
          echo "Creating directory structure..."
          mkdir -p data/rfps data/reports logs
          chmod -R 755 data logs
          
          # Show current working directory and permissions
          echo "Working directory: $(pwd)"
          echo "Directory structure:"
          ls -la
          echo "Data directory permissions:"
          ls -la data/
          
          # Test that the application can initialize
          echo "Testing application initialization..."
          set +e
          timeout 60s npm start status
          STATUS_EXIT_CODE=$?
          set -e
          
          echo "Status command exit code: $STATUS_EXIT_CODE"
          
          # Check what was created
          echo "Checking created files and directories:"
          ls -la data/ || echo "Data directory not found"
          ls -la logs/ || echo "Logs directory not found"
          
          # Check if database was created during initialization
          if [ -f "data/database.sqlite" ]; then
            echo "âœ… Database initialized successfully"
            echo "Database size: $(stat -f%z data/database.sqlite 2>/dev/null || stat -c%s data/database.sqlite) bytes"
          else
            echo "âš ï¸ Database not found after initialization"
          fi
          
          # Check if logs were created
          if [ -f "logs/rfpmart-analyzer.log" ]; then
            echo "âœ… Log file created"
            echo "Last few log entries:"
            tail -5 logs/rfpmart-analyzer.log
          else
            echo "âš ï¸ Log file not found"
          fi

      - name: Run RFP analysis
        run: |
          echo "Starting RFP analysis workflow..."
          
          # Set exit on error temporarily disabled to capture logs
          set +e
          
          # Show current directory structure
          echo "Current directory structure:"
          ls -la
          echo "Data directory:"
          ls -la data/ || echo "Data directory not found"
          
          if [ "${{ github.event.inputs.since_date }}" != "" ]; then
            echo "Running analysis since: ${{ github.event.inputs.since_date }}"
            npm start run -- --since "${{ github.event.inputs.since_date }}"
            ANALYSIS_EXIT_CODE=$?
          else
            echo "Running standard analysis (last run date)"
            npm start run
            ANALYSIS_EXIT_CODE=$?
          fi
          
          echo "Analysis completed with exit code: $ANALYSIS_EXIT_CODE"
          
          # Show final directory structure
          echo "Final directory structure:"
          ls -la data/ || echo "Data directory still not found"
          ls -la logs/ || echo "Logs directory not found"
          
          # Check if exit code indicates failure
          if [ $ANALYSIS_EXIT_CODE -ne 0 ]; then
            echo "âš ï¸ Analysis exited with non-zero code, but continuing to generate reports"
          else
            echo "âœ… Analysis completed successfully"
          fi
          
          # Don't fail the workflow for analysis issues, let artifact upload handle it
          exit 0

      - name: Generate Static Dashboard
        if: always()
        run: |
          echo "ðŸŽ¨ Generating static HTML dashboard..."

          # Generate the dashboard (this will also build if needed)
          set +e
          npm run dashboard
          DASHBOARD_EXIT_CODE=$?
          set -e

          if [ $DASHBOARD_EXIT_CODE -eq 0 ] && [ -f "./data/reports/dashboard.html" ]; then
            echo "âœ… Dashboard generated successfully"

            # Get dashboard file info
            DASHBOARD_SIZE=$(stat -f%z ./data/reports/dashboard.html 2>/dev/null || stat -c%s ./data/reports/dashboard.html)
            echo "ðŸ“Š Dashboard size: $DASHBOARD_SIZE bytes"

            # Count RFPs in dashboard
            RFP_COUNT=$(grep -o '"rfpId":' ./data/reports/dashboard.html | wc -l || echo "0")
            echo "ðŸ“‹ Dashboard contains: $RFP_COUNT RFPs"

            echo "DASHBOARD_GENERATED=true" >> $GITHUB_ENV
          else
            echo "âš ï¸ Dashboard generation failed or file not found"
            echo "DASHBOARD_GENERATED=false" >> $GITHUB_ENV
          fi

          # Always continue to next step
          exit 0

      - name: Check generated reports
        if: always()
        run: |
          echo "Checking for generated reports..."
          
          # Reports are already generated during the main workflow
          # Just check if they exist and list them
          if [ -d "./data/reports" ]; then
            echo "âœ… Reports directory found"
            echo "Report files:"
            find ./data/reports -name "*.md" -o -name "*.html" -o -name "*.json" | head -20
          else
            echo "â„¹ï¸ No reports directory found (no RFPs processed or no high-scoring RFPs)"
          fi
          
          echo "Report check completed"

      - name: Upload persistent database
        if: always()
        run: |
          echo "Uploading updated database to data-store branch..."
          
          # Check if we have a database to upload
          if [ ! -f "./data/database.sqlite" ]; then
            echo "âš ï¸ No database found to upload"
            exit 0
          fi
          
          # Get database info
          DB_SIZE=$(stat -f%z ./data/database.sqlite 2>/dev/null || stat -c%s ./data/database.sqlite)
          echo "Database size: $DB_SIZE bytes"
          
          # Configure git
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Create or switch to data-store branch
          if [ "$NO_PERSISTENT_DATA" = "true" ]; then
            echo "Creating new data-store branch..."
            git checkout --orphan data-store
            git rm -rf .
            echo "# RFP Mart Analyzer Persistent Data Storage" > README.md
            echo "" >> README.md
            echo "This branch stores the persistent SQLite database for the RFP analyzer." >> README.md
            echo "The database is automatically updated by GitHub Actions workflows." >> README.md
            echo "" >> README.md
            echo "Last updated: $(date)" >> README.md
          else
            echo "Switching to existing data-store branch..."
            git checkout -B data-store origin/data-store
          fi
          
          # Copy the updated database
          cp ./data/database.sqlite ./database.sqlite
          
          # Create a backup with timestamp
          TIMESTAMP=$(date -u +"%Y%m%d_%H%M%S")
          cp ./database.sqlite "./database-backup-${TIMESTAMP}.sqlite"
          
          # Clean up old backups (keep last 10)
          ls -t database-backup-*.sqlite 2>/dev/null | tail -n +11 | xargs rm -f || true
          
          # Add files and commit
          git add database.sqlite database-backup-*.sqlite README.md
          
          # Check if there are changes to commit
          if git diff --cached --quiet; then
            echo "No changes to commit to data-store branch"
          else
            git commit -m "ðŸ“Š Update persistent database - $(date '+%Y-%m-%d %H:%M:%S')
            
            Database size: ${DB_SIZE} bytes
            Run: ${{ github.run_number }}
            
            ðŸ¤– Generated with Claude Code
            
            Co-Authored-By: Claude <noreply@anthropic.com>"
            
            git push origin data-store
            echo "âœ… Database uploaded and committed to data-store branch"
          fi
          
          # Switch back to main branch
          git checkout main

      - name: Generate analysis report
        if: always()
        run: |
          echo "## RFP Analysis Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Date:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow:** ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY
          echo "**Run Number:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check various success indicators
          SUCCESS_INDICATORS=0
          
          if [ -f "./data/database.sqlite" ]; then
            echo "âœ… Database created successfully" >> $GITHUB_STEP_SUMMARY
            SUCCESS_INDICATORS=$((SUCCESS_INDICATORS + 1))
          else
            echo "âŒ Database not found" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -d "./data" ]; then
            echo "âœ… Data directory created" >> $GITHUB_STEP_SUMMARY
            SUCCESS_INDICATORS=$((SUCCESS_INDICATORS + 1))
          else
            echo "âŒ Data directory missing" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -d "./logs" ] && [ "$(ls -A ./logs 2>/dev/null)" ]; then
            echo "âœ… Logs generated" >> $GITHUB_STEP_SUMMARY
            SUCCESS_INDICATORS=$((SUCCESS_INDICATORS + 1))
          else
            echo "âš ï¸ No logs found" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Check for RFP processing
          if [ -d "./reports" ] && [ "$(ls -A ./reports 2>/dev/null)" ]; then
            echo "âœ… Reports generated" >> $GITHUB_STEP_SUMMARY
            echo "ðŸ“Š **Report Count:** $(find ./reports -name "*.md" 2>/dev/null | wc -l)" >> $GITHUB_STEP_SUMMARY
            SUCCESS_INDICATORS=$((SUCCESS_INDICATORS + 1))
          else
            echo "â„¹ï¸ No reports generated (no new RFPs or processing issues)" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Overall status
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ $SUCCESS_INDICATORS -ge 2 ]; then
            echo "ðŸŽ‰ **Overall Status:** Workflow completed successfully" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ **Overall Status:** Workflow completed with issues" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Log summary
          if [ -f "./logs/rfpmart-analyzer.log" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Recent Log Activity:" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -20 ./logs/rfpmart-analyzer.log 2>/dev/null || echo "Unable to read log file"
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

      - name: Check for artifacts
        id: check-artifacts
        run: |
          echo "reports_exist=false" >> $GITHUB_OUTPUT
          echo "database_exists=false" >> $GITHUB_OUTPUT
          echo "logs_exist=false" >> $GITHUB_OUTPUT
          echo "high_priority_exist=false" >> $GITHUB_OUTPUT
          
          if [ -d "reports" ] && [ "$(ls -A reports)" ]; then
            echo "reports_exist=true" >> $GITHUB_OUTPUT
          fi
          
          if [ -f "data/database.sqlite" ]; then
            echo "database_exists=true" >> $GITHUB_OUTPUT
          fi
          
          if [ -d "logs" ] && [ "$(ls -A logs)" ]; then
            echo "logs_exist=true" >> $GITHUB_OUTPUT
          fi
          
          if [ -d "reports/rfps" ] && [ "$(ls -A reports/rfps)" ]; then
            echo "high_priority_exist=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit reports to repository
        if: always() && steps.check-artifacts.outputs.reports_exist == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Add the reports directory
          git add reports/
          
          # Check if there are changes to commit
          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            git commit -m "ðŸ“Š Daily RFP Analysis Report - $(date '+%Y-%m-%d')
            
            ðŸ¤– Generated with Claude Code
            
            Co-Authored-By: Claude <noreply@anthropic.com>"
            
            git push
            echo "âœ… Reports committed and pushed to repository"
          fi

      - name: Deploy to GitHub Pages
        if: always() && steps.check-artifacts.outputs.reports_exist == 'true'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./reports/docs
          destination_dir: rfp-reports

      - name: Upload analysis artifacts
        uses: actions/upload-artifact@v4
        if: always() && (steps.check-artifacts.outputs.reports_exist == 'true' || steps.check-artifacts.outputs.database_exists == 'true' || steps.check-artifacts.outputs.logs_exist == 'true')
        with:
          name: rfp-analysis-${{ github.run_number }}
          path: |
            reports/
            logs/
            data/database.sqlite
          retention-days: 30

      - name: Upload high-priority RFPs
        uses: actions/upload-artifact@v4
        if: always() && steps.check-artifacts.outputs.high_priority_exist == 'true'
        with:
          name: high-priority-rfps-${{ github.run_number }}
          path: |
            reports/rfps/
          retention-days: 90

      - name: Notify on high-priority RFPs
        if: success()
        run: |
          # Check if there are any high-priority reports generated
          if [ -d "./reports/rfps" ] && [ "$(ls -A ./reports/rfps)" ]; then
            echo "ðŸŽ¯ High-priority RFPs found! Check the artifacts for detailed reports."
            echo "HIGH_PRIORITY_FOUND=true" >> $GITHUB_ENV
          else
            echo "No high-priority RFPs identified in this run."
            echo "HIGH_PRIORITY_FOUND=false" >> $GITHUB_ENV
          fi

      - name: Create Daily RFP Analysis Summary Issue
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Helper function to safely read files
            function safeReadFile(filePath) {
              try {
                return fs.readFileSync(filePath, 'utf8');
              } catch (error) {
                console.log(`Could not read ${filePath}:`, error.message);
                return null;
              }
            }
            
            // Helper function to format file size
            function formatFileSize(bytes) {
              if (bytes === 0) return '0 Bytes';
              const k = 1024;
              const sizes = ['Bytes', 'KB', 'MB', 'GB'];
              const i = Math.floor(Math.log(bytes) / Math.log(k));
              return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
            }
            
            // Read summary report
            let summaryContent = '';
            let highPriorityRFPs = [];
            let mediumPriorityRFPs = [];
            let totalAnalyzed = 0;
            let averageScore = 0;
            
            try {
              // Look for summary report in data/reports directory
              const reportsDir = './data/reports';
              if (fs.existsSync(reportsDir)) {
                const files = fs.readdirSync(reportsDir);
                const summaryFile = files.find(f => f.startsWith('summary-report-') && f.endsWith('.md'));
                
                if (summaryFile) {
                  const summaryPath = path.join(reportsDir, summaryFile);
                  const content = safeReadFile(summaryPath);
                  
                  if (content) {
                    summaryContent = content;
                    
                    // Extract statistics
                    const totalMatch = content.match(/Total RFPs Analyzed:\*\* (\d+)/);
                    if (totalMatch) totalAnalyzed = parseInt(totalMatch[1]);
                    
                    const avgMatch = content.match(/Average Score:\*\* ([\d.]+)/);
                    if (avgMatch) averageScore = parseFloat(avgMatch[1]);
                    
                    // Extract high priority RFPs section
                    const highPriorityMatch = content.match(/## ðŸš€ High Priority RFPs \((\d+)\)(.*?)(?=##|$)/s);
                    if (highPriorityMatch) {
                      const count = parseInt(highPriorityMatch[1]);
                      const section = highPriorityMatch[2];
                      
                      // Extract individual RFP details
                      const rfpMatches = section.matchAll(/### (.+?)\n- \*\*Score:\*\* (.+?)\n- \*\*Institution:\*\* (.+?)\n(?:- \*\*Budget:\*\* (.+?)\n)?(?:- \*\*CMS:\*\* (.+?)\n)?- \*\*Reasoning:\*\* (.+?)\n/g);
                      
                      for (const match of rfpMatches) {
                        highPriorityRFPs.push({
                          title: match[1],
                          score: match[2],
                          institution: match[3],
                          budget: match[4] || 'Not specified',
                          cms: match[5] || 'Not specified',
                          reasoning: match[6]
                        });
                      }
                    }
                    
                    // Extract medium priority RFPs section
                    const mediumPriorityMatch = content.match(/## âš¡ Medium Priority RFPs \((\d+)\)(.*?)(?=##|$)/s);
                    if (mediumPriorityMatch) {
                      const section = mediumPriorityMatch[2];
                      
                      // Extract individual RFP details
                      const rfpMatches = section.matchAll(/- \*\*(.+?)\*\* - Score: (.+?)%\n(?:  - Institution: (.+?)\n)?(?:  - Budget: (.+?)\n)?/g);
                      
                      for (const match of rfpMatches) {
                        mediumPriorityRFPs.push({
                          title: match[1],
                          score: match[2] + '%',
                          institution: match[3] || 'Not specified',
                          budget: match[4] || 'Not specified'
                        });
                      }
                    }
                  }
                }
              }
            } catch (error) {
              console.log('Error reading summary report:', error.message);
            }
            
            // Get database information
            let databaseInfo = '';
            try {
              const dbPath = './data/database.sqlite';
              if (fs.existsSync(dbPath)) {
                const stats = fs.statSync(dbPath);
                databaseInfo = `ðŸ“Š **Database:** ${formatFileSize(stats.size)} (Updated: ${stats.mtime.toISOString()})`;
              }
            } catch (error) {
              console.log('Could not read database info:', error.message);
            }
            
            // List individual RFP reports
            let individualReports = [];
            try {
              const individualDir = './data/reports/individual';
              if (fs.existsSync(individualDir)) {
                const files = fs.readdirSync(individualDir);
                individualReports = files.filter(f => f.endsWith('.md')).slice(0, 10); // Limit to 10
              }
            } catch (error) {
              console.log('Could not read individual reports:', error.message);
            }
            
            // Create issue content
            const runDate = new Date().toISOString().split('T')[0];
            const runTime = new Date().toISOString().split('T')[1].split('.')[0];
            
            let issueTitle, issueLabels;
            
            if (highPriorityRFPs.length > 0) {
              issueTitle = `ðŸŽ¯ ${highPriorityRFPs.length} High-Priority RFPs Found - ${runDate}`;
              issueLabels = ['rfp', 'high-priority', 'action-required', 'automated'];
            } else {
              issueTitle = `ðŸ“Š Daily RFP Analysis Summary - ${runDate}`;
              issueLabels = ['rfp', 'daily-summary', 'automated'];
            }
            
            const issueBody = `# Daily RFP Analysis Results
            
            **Run Date:** ${runDate} at ${runTime} UTC  
            **Workflow Run:** [#${{ github.run_number }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})  
            **Status:** ${totalAnalyzed > 0 ? 'âœ… Completed Successfully' : 'âš ï¸ No RFPs Analyzed'}
            
            ${databaseInfo}
            
            ## ðŸ“ˆ Summary Statistics
            
            - **Total RFPs Analyzed:** ${totalAnalyzed}
            - **Average Score:** ${averageScore}
            - **High Priority RFPs:** ${highPriorityRFPs.length}
            - **Medium Priority RFPs:** ${mediumPriorityRFPs.length}
            
            ${highPriorityRFPs.length > 0 ? `
            ## ðŸš€ HIGH-PRIORITY OPPORTUNITIES (IMMEDIATE ACTION REQUIRED)
            
            ${highPriorityRFPs.map((rfp, index) => `
            ### ${index + 1}. ${rfp.title}
            
            - **ðŸ“Š Score:** ${rfp.score}
            - **ðŸ« Institution:** ${rfp.institution}
            - **ðŸ’° Budget:** ${rfp.budget}
            - **ðŸ’» CMS:** ${rfp.cms}
            - **ðŸŽ¯ Why It's a Good Fit:** ${rfp.reasoning}
            
            **Action Items:**
            - [ ] Review detailed analysis report
            - [ ] Check proposal deadline
            - [ ] Assign team member
            - [ ] Begin proposal preparation
            
            ---
            `).join('')}
            
            ## ðŸ“‹ Next Steps for High-Priority RFPs:
            1. **Immediate Review:** Download and review individual RFP reports
            2. **Due Date Check:** Verify proposal deadlines in source documents
            3. **Team Assignment:** Assign experienced team members to high-scoring opportunities
            4. **Proposal Planning:** Begin proposal development for highest-scoring RFPs
            5. **Client Research:** Research institutions for better proposal customization
            ` : ''}
            
            ${mediumPriorityRFPs.length > 0 ? `
            ## âš¡ Medium Priority Opportunities
            
            ${mediumPriorityRFPs.slice(0, 5).map((rfp, index) => `
            **${index + 1}. ${rfp.title}** (Score: ${rfp.score})
            - Institution: ${rfp.institution}
            - Budget: ${rfp.budget}
            `).join('\n')}
            
            ${mediumPriorityRFPs.length > 5 ? `\n*...and ${mediumPriorityRFPs.length - 5} more medium-priority RFPs*` : ''}
            ` : ''}
            
            ## ðŸ“ Download Reports & Data

            ${process.env.DASHBOARD_GENERATED === 'true' ? `
            ### ðŸŽ¯ Interactive Dashboard (Click to View!)
            - **[ðŸ“Š Live RFP Dashboard](https://${context.repo.owner}.github.io/${context.repo.repo}/rfp-reports/dashboard.html)** - ðŸ“± **Mobile-friendly interactive dashboard** - Perfect for non-technical users!
            - **[ðŸ“Š Dashboard (GitHub View)](https://github.com/${context.repo.owner}/${context.repo.repo}/blob/main/data/reports/dashboard.html)** - View directly in GitHub

            > ðŸ’¡ **For Non-Technical Users:** Click the "Live RFP Dashboard" link above for an easy-to-use interface showing all RFP opportunities with search, filtering, and export capabilities. No technical knowledge required!

            ` : ''}

            ### ðŸ“Š Main Reports
            - **[ðŸ“‹ Complete Analysis Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})** - Download artifacts ZIP
            - **[ðŸ“ˆ Summary Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})** - Executive summary with all findings
            - **[ðŸ“„ Individual RFP Reports](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})** - Detailed analysis for each high-priority RFP
            
            ### ðŸ’¾ Database & Raw Data
            - **[ðŸ—„ï¸ Updated Database](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})** - SQLite database with all RFP data
            - **[ðŸ“œ Processing Logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})** - Complete workflow execution logs
            
            ${individualReports.length > 0 ? `
            ### ðŸ“‹ Individual RFP Analysis Reports Available:
            ${individualReports.map(report => `- ${report.replace('.md', '').replace('rfp-', 'RFP ')}`).join('\n')}
            ` : ''}
            
            ## ðŸ”— Quick Links
            
            - **[ðŸ“Š View Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})** - See complete execution details
            - **[â¬‡ï¸ Download All Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})** - Get artifacts ZIP file
            - **[ðŸ“ˆ Analysis Dashboard](https://github.com/${{ github.repository }}/actions)** - View historical analysis runs
            - **[âš™ï¸ Workflow Configuration](https://github.com/${{ github.repository }}/blob/main/.github/workflows/daily-rfp-analysis.yml)** - Review automation settings
            
            ${totalAnalyzed === 0 ? `
            ## âš ï¸ No RFPs Analyzed
            
            This run did not analyze any RFPs. This could be because:
            - No new RFPs were found since the last run
            - RFP Mart website had access issues
            - Processing errors occurred (check logs)
            
            **Recommended Actions:**
            1. Check the workflow logs for any errors
            2. Verify RFP Mart credentials are working
            3. Consider running a manual analysis with a different date range
            ` : ''}
            
            ---
            
            **ðŸ¤– This issue was automatically created by the RFP Mart Analyzer**  
            **ðŸ“… Next automated run:** Tomorrow at 9 AM EST  
            **â“ Questions?** Check the [project documentation](https://github.com/${{ github.repository }}) or contact the development team
            
            > **ðŸ’¡ Pro Tip:** Close this issue once you've reviewed all high-priority opportunities and assigned them to team members.
            `;
            
            // Create the issue
            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: issueTitle,
              body: issueBody,
              labels: issueLabels,
              assignees: ['kwall1']
            });
            
            console.log(`Created issue #${issue.data.number}: ${issueTitle}`);
            
            // If there are high-priority RFPs, also add a comment with quick action checklist
            if (highPriorityRFPs.length > 0) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issue.data.number,
                body: `## ðŸŽ¯ Quick Action Checklist for High-Priority RFPs
                
                Use this checklist to track your progress on the ${highPriorityRFPs.length} high-priority opportunities:
                
                ${highPriorityRFPs.map((rfp, index) => `
                ### ${rfp.title}
                - [ ] Downloaded and reviewed detailed analysis report
                - [ ] Checked proposal deadline and requirements
                - [ ] Researched institution background
                - [ ] Assigned team member: ________________
                - [ ] Created proposal timeline
                - [ ] Decision: **Pursue** / **Pass** / **Monitor**
                `).join('\n')}
                
                **ðŸŽ¯ Focus on RFPs with highest scores first!**
                
                ---
                *Check off items as you complete them. Feel free to assign team members and add due dates.*`
              });
            }

      - name: Upload artifacts (backup)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: rfp-analysis-results-${{ github.run_number }}
          path: |
            ./data/
            ./logs/
            ./reports/
          retention-days: 30
          if-no-files-found: warn

      - name: Cleanup on failure
        if: failure()
        run: |
          echo "âŒ Analysis workflow failed. Check logs for details."
          
          # Upload error logs for debugging
          if [ -f "./logs/rfpmart-analyzer.log" ]; then
            echo "Error logs:" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -50 ./logs/rfpmart-analyzer.log >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi