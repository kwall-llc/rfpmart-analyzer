name: Daily RFP Analysis

on:
  schedule:
    # Run daily at 9 AM EST (1 PM UTC)
    - cron: '0 13 * * *'
  workflow_dispatch:
    inputs:
      since_date:
        description: 'Only process RFPs since this date (YYYY-MM-DD)'
        required: false
        type: string
      force_full_run:
        description: 'Force full analysis workflow'
        required: false
        type: boolean
        default: false

env:
  NODE_ENV: production

permissions:
  contents: write  # Allow pushing to repository

jobs:
  rfp-analysis:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install chromium

      - name: Build project
        run: npm run build

      - name: Create environment file
        run: |
          echo "RFPMART_USERNAME=${{ secrets.RFPMART_USERNAME }}" >> .env
          echo "RFPMART_PASSWORD=${{ secrets.RFPMART_PASSWORD }}" >> .env
          echo "RFP_CATEGORY_URL=https://www.rfpmart.com/web-design-and-development-rfp-government-contract.html" >> .env
          echo "MIN_BUDGET_ACCEPTABLE=50000" >> .env
          echo "MIN_BUDGET_PREFERRED=100000" >> .env
          echo "DATA_DIRECTORY=./data" >> .env
          echo "REPORTS_DIRECTORY=./data/reports" >> .env
          echo "RFPS_DIRECTORY=./data/rfps" >> .env
          echo "DATABASE_PATH=./data/database.sqlite" >> .env
          echo "LOG_LEVEL=info" >> .env
          echo "LOG_FILE=./logs/rfpmart-analyzer.log" >> .env
          echo "NODE_ENV=production" >> .env
          echo "HIGHER_ED_KEYWORDS=university,college,school,education,academic,campus,student,institution,district,system" >> .env
          echo "CMS_KEYWORDS_PREFERRED=drupal,wordpress,modern campus" >> .env
          echo "CMS_KEYWORDS_ACCEPTABLE=joomla,craft,contentful,strapi,sitecore,umbraco" >> .env
          echo "PROJECT_TYPE_KEYWORDS=redesign,migration,rebuild,modernize,refresh,overhaul,revamp" >> .env
          echo "TECHNICAL_KEYWORDS=responsive,mobile,accessibility,wcag,ada,508,mobile-first,progressive" >> .env
          echo "LOCATION_PREFERRED=united states,usa,america,north america" >> .env
          echo "LOCATION_ACCEPTABLE=canada,remote,virtual,distributed,online" >> .env
          echo "AI_PROVIDER=openai" >> .env
          echo "AI_OPENAI_API_KEY=${{ secrets.AI_OPENAI_API_KEY }}" >> .env
          echo "AI_OPENAI_MODEL=gpt-4" >> .env
          echo "CLEANUP_ENABLED=true" >> .env
          echo "CLEANUP_POOR_FIT_THRESHOLD=30" >> .env
          echo "CLEANUP_REJECTED_THRESHOLD=50" >> .env

      - name: Create data directories
        run: |
          mkdir -p data/rfps
          mkdir -p data/reports
          mkdir -p data-store
          mkdir -p logs

      - name: Download persistent database
        run: |
          echo "Downloading persistent database from data-store branch..."
          
          # Create orphan branch for data storage if it doesn't exist
          git fetch origin data-store || {
            echo "data-store branch doesn't exist yet, will create it after analysis"
            echo "NO_PERSISTENT_DATA=true" >> $GITHUB_ENV
            exit 0
          }
          
          # Switch to data-store branch and copy database
          git checkout -b data-store origin/data-store
          
          if [ -f "database.sqlite" ]; then
            echo "âœ… Found persistent database"
            cp database.sqlite ./data-store/database.sqlite
            
            # Get database info
            echo "Database size: $(stat -f%z database.sqlite 2>/dev/null || stat -c%s database.sqlite) bytes"
            echo "Database modified: $(stat -f%Sm database.sqlite 2>/dev/null || stat -c%y database.sqlite)"
            
            echo "PERSISTENT_DATABASE_FOUND=true" >> $GITHUB_ENV
          else
            echo "â„¹ï¸ No persistent database found on data-store branch"
            echo "PERSISTENT_DATABASE_FOUND=false" >> $GITHUB_ENV
          fi
          
          # Switch back to main branch
          git checkout main
          
          # Show what we have
          echo "Data store directory contents:"
          ls -la data-store/ || echo "data-store directory empty"

      - name: Initialize application and database
        run: |
          echo "Initializing RFP Mart Analyzer..."
          
          # Verify environment file was created
          if [ -f ".env" ]; then
            echo "âœ… Environment file exists"
            echo "Environment variables:"
            grep -E "^[A-Z_]+=" .env | head -5
          else
            echo "âŒ Environment file missing"
            exit 1
          fi
          
          # Show Node.js and npm versions
          echo "Node.js version: $(node --version)"
          echo "npm version: $(npm --version)"
          
          # Pre-create directory structure for GitHub Actions
          echo "Creating directory structure..."
          mkdir -p data/rfps data/reports logs
          chmod -R 755 data logs
          
          # Show current working directory and permissions
          echo "Working directory: $(pwd)"
          echo "Directory structure:"
          ls -la
          echo "Data directory permissions:"
          ls -la data/
          
          # Test that the application can initialize
          echo "Testing application initialization..."
          set +e
          timeout 60s npm start status
          STATUS_EXIT_CODE=$?
          set -e
          
          echo "Status command exit code: $STATUS_EXIT_CODE"
          
          # Check what was created
          echo "Checking created files and directories:"
          ls -la data/ || echo "Data directory not found"
          ls -la logs/ || echo "Logs directory not found"
          
          # Check if database was created during initialization
          if [ -f "data/database.sqlite" ]; then
            echo "âœ… Database initialized successfully"
            echo "Database size: $(stat -f%z data/database.sqlite 2>/dev/null || stat -c%s data/database.sqlite) bytes"
          else
            echo "âš ï¸ Database not found after initialization"
          fi
          
          # Check if logs were created
          if [ -f "logs/rfpmart-analyzer.log" ]; then
            echo "âœ… Log file created"
            echo "Last few log entries:"
            tail -5 logs/rfpmart-analyzer.log
          else
            echo "âš ï¸ Log file not found"
          fi

      - name: Run RFP analysis
        run: |
          echo "Starting RFP analysis workflow..."
          
          # Set exit on error temporarily disabled to capture logs
          set +e
          
          # Show current directory structure
          echo "Current directory structure:"
          ls -la
          echo "Data directory:"
          ls -la data/ || echo "Data directory not found"
          
          if [ "${{ github.event.inputs.since_date }}" != "" ]; then
            echo "Running analysis since: ${{ github.event.inputs.since_date }}"
            npm start run -- --since "${{ github.event.inputs.since_date }}"
            ANALYSIS_EXIT_CODE=$?
          else
            echo "Running standard analysis (last run date)"
            npm start run
            ANALYSIS_EXIT_CODE=$?
          fi
          
          echo "Analysis completed with exit code: $ANALYSIS_EXIT_CODE"
          
          # Show final directory structure
          echo "Final directory structure:"
          ls -la data/ || echo "Data directory still not found"
          ls -la logs/ || echo "Logs directory not found"
          
          # Check if exit code indicates failure
          if [ $ANALYSIS_EXIT_CODE -ne 0 ]; then
            echo "âš ï¸ Analysis exited with non-zero code, but continuing to generate reports"
          else
            echo "âœ… Analysis completed successfully"
          fi
          
          # Don't fail the workflow for analysis issues, let artifact upload handle it
          exit 0

      - name: Check generated reports
        if: always()
        run: |
          echo "Checking for generated reports..."
          
          # Reports are already generated during the main workflow
          # Just check if they exist and list them
          if [ -d "./data/reports" ]; then
            echo "âœ… Reports directory found"
            echo "Report files:"
            find ./data/reports -name "*.md" -o -name "*.html" -o -name "*.json" | head -20
          else
            echo "â„¹ï¸ No reports directory found (no RFPs processed or no high-scoring RFPs)"
          fi
          
          echo "Report check completed"

      - name: Upload persistent database
        if: always()
        run: |
          echo "Uploading updated database to data-store branch..."
          
          # Check if we have a database to upload
          if [ ! -f "./data/database.sqlite" ]; then
            echo "âš ï¸ No database found to upload"
            exit 0
          fi
          
          # Get database info
          DB_SIZE=$(stat -f%z ./data/database.sqlite 2>/dev/null || stat -c%s ./data/database.sqlite)
          echo "Database size: $DB_SIZE bytes"
          
          # Configure git
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Create or switch to data-store branch
          if [ "$NO_PERSISTENT_DATA" = "true" ]; then
            echo "Creating new data-store branch..."
            git checkout --orphan data-store
            git rm -rf .
            echo "# RFP Mart Analyzer Persistent Data Storage" > README.md
            echo "" >> README.md
            echo "This branch stores the persistent SQLite database for the RFP analyzer." >> README.md
            echo "The database is automatically updated by GitHub Actions workflows." >> README.md
            echo "" >> README.md
            echo "Last updated: $(date)" >> README.md
          else
            echo "Switching to existing data-store branch..."
            git checkout -B data-store origin/data-store
          fi
          
          # Copy the updated database
          cp ./data/database.sqlite ./database.sqlite
          
          # Create a backup with timestamp
          TIMESTAMP=$(date -u +"%Y%m%d_%H%M%S")
          cp ./database.sqlite "./database-backup-${TIMESTAMP}.sqlite"
          
          # Clean up old backups (keep last 10)
          ls -t database-backup-*.sqlite 2>/dev/null | tail -n +11 | xargs rm -f || true
          
          # Add files and commit
          git add database.sqlite database-backup-*.sqlite README.md
          
          # Check if there are changes to commit
          if git diff --cached --quiet; then
            echo "No changes to commit to data-store branch"
          else
            git commit -m "ðŸ“Š Update persistent database - $(date '+%Y-%m-%d %H:%M:%S')
            
            Database size: ${DB_SIZE} bytes
            Run: ${{ github.run_number }}
            
            ðŸ¤– Generated with Claude Code
            
            Co-Authored-By: Claude <noreply@anthropic.com>"
            
            git push origin data-store
            echo "âœ… Database uploaded and committed to data-store branch"
          fi
          
          # Switch back to main branch
          git checkout main

      - name: Generate analysis report
        if: always()
        run: |
          echo "## RFP Analysis Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Date:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow:** ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY
          echo "**Run Number:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check various success indicators
          SUCCESS_INDICATORS=0
          
          if [ -f "./data/database.sqlite" ]; then
            echo "âœ… Database created successfully" >> $GITHUB_STEP_SUMMARY
            SUCCESS_INDICATORS=$((SUCCESS_INDICATORS + 1))
          else
            echo "âŒ Database not found" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -d "./data" ]; then
            echo "âœ… Data directory created" >> $GITHUB_STEP_SUMMARY
            SUCCESS_INDICATORS=$((SUCCESS_INDICATORS + 1))
          else
            echo "âŒ Data directory missing" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -d "./logs" ] && [ "$(ls -A ./logs 2>/dev/null)" ]; then
            echo "âœ… Logs generated" >> $GITHUB_STEP_SUMMARY
            SUCCESS_INDICATORS=$((SUCCESS_INDICATORS + 1))
          else
            echo "âš ï¸ No logs found" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Check for RFP processing
          if [ -d "./reports" ] && [ "$(ls -A ./reports 2>/dev/null)" ]; then
            echo "âœ… Reports generated" >> $GITHUB_STEP_SUMMARY
            echo "ðŸ“Š **Report Count:** $(find ./reports -name "*.md" 2>/dev/null | wc -l)" >> $GITHUB_STEP_SUMMARY
            SUCCESS_INDICATORS=$((SUCCESS_INDICATORS + 1))
          else
            echo "â„¹ï¸ No reports generated (no new RFPs or processing issues)" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Overall status
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ $SUCCESS_INDICATORS -ge 2 ]; then
            echo "ðŸŽ‰ **Overall Status:** Workflow completed successfully" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ **Overall Status:** Workflow completed with issues" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Log summary
          if [ -f "./logs/rfpmart-analyzer.log" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Recent Log Activity:" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -20 ./logs/rfpmart-analyzer.log 2>/dev/null || echo "Unable to read log file"
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

      - name: Check for artifacts
        id: check-artifacts
        run: |
          echo "reports_exist=false" >> $GITHUB_OUTPUT
          echo "database_exists=false" >> $GITHUB_OUTPUT
          echo "logs_exist=false" >> $GITHUB_OUTPUT
          echo "high_priority_exist=false" >> $GITHUB_OUTPUT
          
          if [ -d "reports" ] && [ "$(ls -A reports)" ]; then
            echo "reports_exist=true" >> $GITHUB_OUTPUT
          fi
          
          if [ -f "data/database.sqlite" ]; then
            echo "database_exists=true" >> $GITHUB_OUTPUT
          fi
          
          if [ -d "logs" ] && [ "$(ls -A logs)" ]; then
            echo "logs_exist=true" >> $GITHUB_OUTPUT
          fi
          
          if [ -d "reports/rfps" ] && [ "$(ls -A reports/rfps)" ]; then
            echo "high_priority_exist=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit reports to repository
        if: always() && steps.check-artifacts.outputs.reports_exist == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Add the reports directory
          git add reports/
          
          # Check if there are changes to commit
          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            git commit -m "ðŸ“Š Daily RFP Analysis Report - $(date '+%Y-%m-%d')
            
            ðŸ¤– Generated with Claude Code
            
            Co-Authored-By: Claude <noreply@anthropic.com>"
            
            git push
            echo "âœ… Reports committed and pushed to repository"
          fi

      - name: Deploy to GitHub Pages
        if: always() && steps.check-artifacts.outputs.reports_exist == 'true'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./reports/docs
          destination_dir: rfp-reports

      - name: Upload analysis artifacts
        uses: actions/upload-artifact@v4
        if: always() && (steps.check-artifacts.outputs.reports_exist == 'true' || steps.check-artifacts.outputs.database_exists == 'true' || steps.check-artifacts.outputs.logs_exist == 'true')
        with:
          name: rfp-analysis-${{ github.run_number }}
          path: |
            reports/
            logs/
            data/database.sqlite
          retention-days: 30

      - name: Upload high-priority RFPs
        uses: actions/upload-artifact@v4
        if: always() && steps.check-artifacts.outputs.high_priority_exist == 'true'
        with:
          name: high-priority-rfps-${{ github.run_number }}
          path: |
            reports/rfps/
          retention-days: 90

      - name: Notify on high-priority RFPs
        if: success()
        run: |
          # Check if there are any high-priority reports generated
          if [ -d "./reports/rfps" ] && [ "$(ls -A ./reports/rfps)" ]; then
            echo "ðŸŽ¯ High-priority RFPs found! Check the artifacts for detailed reports."
            echo "HIGH_PRIORITY_FOUND=true" >> $GITHUB_ENV
          else
            echo "No high-priority RFPs identified in this run."
            echo "HIGH_PRIORITY_FOUND=false" >> $GITHUB_ENV
          fi

      - name: Create GitHub Issue for High-Priority RFPs
        if: env.HIGH_PRIORITY_FOUND == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Read the summary report if it exists
            let reportContent = 'High-priority RFPs have been identified in the latest analysis run.';
            
            try {
              const reportsDir = './reports';
              const files = fs.readdirSync(reportsDir);
              const summaryFile = files.find(f => f.startsWith('README.md'));
              
              if (summaryFile) {
                const summaryPath = path.join(reportsDir, summaryFile);
                const content = fs.readFileSync(summaryPath, 'utf8');
                
                // Extract just the high-priority section
                const highPriorityMatch = content.match(/## ðŸŽ¯ Excellent Fit RFPs.*?(?=##|$)/s);
                if (highPriorityMatch) {
                  reportContent = highPriorityMatch[0];
                }
              }
            } catch (error) {
              console.log('Could not read summary report:', error.message);
            }
            
            const issueTitle = `ðŸŽ¯ High-Priority RFPs Found - ${new Date().toISOString().split('T')[0]}`;
            const issueBody = `# High-Priority RFPs Detected
            
            The automated RFP analysis has identified high-priority opportunities that match KWALL's criteria.
            
            ## Quick Actions Required:
            1. Review the attached analysis reports
            2. Evaluate RFPs for immediate pursuit
            3. Assign team members for proposal development
            4. Check due dates and plan accordingly
            
            ## Analysis Details:
            
            ${reportContent}
            
            ## Artifacts:
            - Check the [workflow run artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) for detailed reports
            - Look for high-priority individual RFP reports
            - View online dashboard at [GitHub Pages](https://${context.repo.owner}.github.io/${context.repo.repo}/rfp-reports/)
            
            ---
            *This issue was automatically created by the RFP Mart Analyzer workflow.*
            `;
            
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: issueTitle,
              body: issueBody,
              labels: ['rfp', 'high-priority', 'automated']
            });

      - name: Upload artifacts (backup)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: rfp-analysis-results-${{ github.run_number }}
          path: |
            ./data/
            ./logs/
            ./reports/
          retention-days: 30
          if-no-files-found: warn

      - name: Cleanup on failure
        if: failure()
        run: |
          echo "âŒ Analysis workflow failed. Check logs for details."
          
          # Upload error logs for debugging
          if [ -f "./logs/rfpmart-analyzer.log" ]; then
            echo "Error logs:" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -50 ./logs/rfpmart-analyzer.log >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi